{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f520db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "next is whole data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "dt=load_wine()\n",
    "print(dir(dt))\n",
    "\n",
    "print('-'*90+ '\\n'*3 + 'next is whole data')\n",
    "dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4ab6c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt_data = dt.data\n",
    "dt_label = dt.target\n",
    "print(dt_data.shape)\n",
    "\n",
    "\n",
    "dt_df = pd.DataFrame(data=dt_data, columns=dt.feature_names)\n",
    "dt_df[\"label\"] = dt.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dt_data, \n",
    "                                                    dt_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c8de263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36, 13), (36,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e22fb",
   "metadata": {},
   "source": [
    "y_pred 는 예측 값 입니다. \n",
    "정확도 = 예측 결과가 정답인 데이터의 개수 / 예측한 전체 데이터의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e97c72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "       1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a2d0ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "       1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f75c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5251fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "704506aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.16666667, 0.83333333]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)\n",
    "array = confusion_matrix(y_test, y_pred) \n",
    "total = np.sum(array, axis = 1)\n",
    "array1 = array / total[:,None]\n",
    "t1 = array1\n",
    "array1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83fbef",
   "metadata": {},
   "source": [
    "### axis = 1 은 행 단위로 더했다는 뜻입니다.\n",
    "Confusion matrix 를 보면 decision tree 의 결과는 다음과 같습니다\n",
    "다음은 random_forest 를 보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4587fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.16666667, 0.83333333]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy\n",
    "confusion_matrix(y_test, y_pred)\n",
    "array2 = confusion_matrix(y_test, y_pred) \n",
    "total2 = np.sum(array, axis = 1)\n",
    "array2 = array / total2[:,None]\n",
    "t2 = array2\n",
    "array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48eaa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43b4af24",
   "metadata": {},
   "source": [
    "정확도에 있어서 차이가 없습니다.  \n",
    "confusion_matrix 를 보았을 때 틀린 경우가 없습니다. 좋습니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40586188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85714286, 0.        , 0.14285714],\n",
       "       [0.05882353, 0.88235294, 0.05882353],\n",
       "       [0.        , 0.91666667, 0.08333333]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "svm_model = svm.SVC()\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred) \n",
    "\n",
    "array = confusion_matrix(y_test, y_pred) \n",
    "total = np.sum(array, axis = 1)\n",
    "array3 = array / total[:,None]\n",
    "t3 = array3\n",
    "array3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6307812",
   "metadata": {},
   "source": [
    "svm 모델은 조금 차이가 있습니다. 앞서 비교해보았을때 정확도가 훅 떨어집니다. \n",
    "2을 주었을 때 1,3 으로 대답한 게 한개씩 있어서 오류가 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95375908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54         7\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.36      0.57      0.41        36\n",
      "weighted avg       0.40      0.53      0.44        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [0.29411765, 0.70588235, 0.        ],\n",
       "       [0.58333333, 0.41666667, 0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "array = confusion_matrix(y_test, y_pred) \n",
    "total = np.sum(array, axis = 1)\n",
    "array4 = array / total[:,None]\n",
    "t4 = array4\n",
    "array4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d527d14",
   "metadata": {},
   "source": [
    "### sgd 모델도 정확도가 떨어집니다.\n",
    "특히 2번(3번째 레이블) 의 정확도가 꽤 떨어집니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "350a0457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.95      0.96        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85714286, 0.14285714, 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "array = confusion_matrix(y_test, y_pred) \n",
    "total = np.sum(array, axis = 1)\n",
    "array5 = array / total[:,None]\n",
    "t5 = array5\n",
    "array5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d7ec9",
   "metadata": {},
   "source": [
    "선형회귀 모델이 그나마 앞선 모델들 보다 낫습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c413f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "decision forest\n",
      "\n",
      "\n",
      "[[1.         0.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.16666667 0.83333333]]\n",
      "\n",
      "\n",
      "[1.         1.16666667 0.83333333]\n",
      "------------------------------------------------------------------------------------------\n",
      "random forest\n",
      "\n",
      "\n",
      "[[1.         0.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.16666667 0.83333333]]\n",
      "\n",
      "\n",
      "[1.         1.16666667 0.83333333]\n",
      "------------------------------------------------------------------------------------------\n",
      "svm model\n",
      "\n",
      "\n",
      "[[0.85714286 0.         0.14285714]\n",
      " [0.05882353 0.88235294 0.05882353]\n",
      " [0.         0.91666667 0.08333333]]\n",
      "\n",
      "\n",
      "[0.91596639 1.79901961 0.28501401]\n",
      "------------------------------------------------------------------------------------------\n",
      "sgd model\n",
      "\n",
      "\n",
      "[[1.         0.         0.        ]\n",
      " [0.29411765 0.70588235 0.        ]\n",
      " [0.58333333 0.41666667 0.        ]]\n",
      "\n",
      "\n",
      "[1.87745098 1.12254902 0.        ]\n",
      "------------------------------------------------------------------------------------------\n",
      "logistic model\n",
      "\n",
      "\n",
      "[[0.85714286 0.14285714 0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.         1.        ]]\n",
      "\n",
      "\n",
      "[0.85714286 1.14285714 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print('-'*90)\n",
    "print('decision forest')\n",
    "print('\\n')\n",
    "print(t1)\n",
    "print('\\n')\n",
    "\n",
    "x1 = t1.sum(axis = 0)\n",
    "\n",
    "print(x1)\n",
    "\n",
    "\n",
    "print('-'*90)\n",
    "print('random forest')\n",
    "print('\\n')\n",
    "print(t2)\n",
    "x2 = t2.sum(axis = 0)\n",
    "print('\\n')\n",
    "print(x2)\n",
    "\n",
    "print('-'*90)\n",
    "print('svm model')\n",
    "print('\\n')\n",
    "print(t3)\n",
    "print('\\n')\n",
    "x3 = t3.sum(axis = 0)\n",
    "print(x3)\n",
    "\n",
    "print('-'*90)\n",
    "print('sgd model')\n",
    "print('\\n')\n",
    "print(t4)\n",
    "print('\\n')\n",
    "x4 = t4.sum(axis = 0)\n",
    "print(x4)\n",
    "\n",
    "\n",
    "print('-'*90)\n",
    "print('logistic model')\n",
    "print('\\n')\n",
    "print(t5)\n",
    "print('\\n')\n",
    "x5 = t5.sum(axis = 0)\n",
    "print(x5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb04ac5",
   "metadata": {},
   "source": [
    "## axis=0 으로 열 단위로 더하니까 많은 숫자가 나온 열이 문제가 있다는 뜻이 된다.\n",
    "svm 모델에서는 2열이 즉, 2번째 레이블을 예측할때 많은 실패가 있었다.\n",
    "행, 렬의 대각 라인만 더하는 함수를 짜고 싶었는데 잘 안되었다\n",
    "결과를 이렇게 한번에 보니까 svm 모델이 문제가 꽤 많다.\n",
    "\n",
    "SVM은 분류에 사용되는 지도학습 머신러닝 모델이다.\n",
    "SVM은 서포트 벡터(support vectors)를 사용해서 결정 경계(Decision Boundary)를 정의하고, 분류되지 않은 점을 해당 결정 경계와 비교해서 분류한다.\n",
    "서포트 벡터(support vectors)는 결정 경계에 가장 가까운 각 클래스의 점들이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b0f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765e2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
